{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ip5m5Gefppr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Base Model"
      ],
      "metadata": {
        "id": "xTCUUxjfakrk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1x1-ekKHadYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Imports\n",
        "import os\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import TextLoader, WikipediaLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# üìÑ Load documents: local + Wikipedia\n",
        "local_loader = TextLoader(\"extracted_text.txt\")  # üîÅ Replace with your actual file\n",
        "wiki_loader = WikipediaLoader(query=\"New Delhi is the Capital of India\", load_max_docs=2)\n",
        "\n",
        "docs = local_loader.load() + wiki_loader.load()\n",
        "\n",
        "# ‚úÇÔ∏è Split documents into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "split_docs = splitter.split_documents(docs)\n",
        "\n",
        "# üîç Embed and store in Chroma\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma.from_documents(split_docs, embedding_model)\n",
        "\n",
        "# ü§ñ Load local model with transformers\n",
        "local_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", max_length=256, truncation=True)\n",
        "llm = HuggingFacePipeline(pipeline=local_pipeline)\n",
        "\n",
        "# üîó Create RAG chain\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
        "\n",
        "# üß† Define response function\n",
        "def generate_response(question):\n",
        "    try:\n",
        "        response = rag_chain.invoke({\"query\": question})\n",
        "        answer = response[\"result\"]\n",
        "        sources = response.get(\"source_documents\", [])\n",
        "\n",
        "        if not sources:\n",
        "            return \"**Answer (fallback):**\\nThis question is outside the scope of the provided documents.\"\n",
        "\n",
        "        source_text = \"\\n\\n\".join([doc.page_content for doc in sources])\n",
        "        return f\"**Answer:**\\n{answer}\\n\\n**Sources:**\\n{source_text}\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "# üéõÔ∏è Launch Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"üåê RAG QA with Local + Wikipedia Knowledge\",\n",
        "    description=\"Ask questions based on local documents and Wikipedia. Powered by LangChain, Chroma, and Hugging Face's flan-t5-base running locally.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "CRM3nzXdSfpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wk4CZClMWBzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gc5Eq9aXWB2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4MseUhSqWB72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADOFmGf4WB-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yst650JWCBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_K0zI1LSfyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zfsMHybSSf0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Km_Dbg2YSf3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRaNvR6PSf58"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}